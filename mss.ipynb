{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processing complete and saved to CSV files.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import Counter\n",
    "\n",
    "# Define the directory where the data files are stored\n",
    "data_dir = \"C:/Users/sarma/Desktop/dataset/Dataset/\"\n",
    "\n",
    "# Create a function to load and process the data for a given year\n",
    "def load_and_process_data(year, data_dir):\n",
    "    # Initialize an empty dataframe to store the data for the specific year\n",
    "    data = pd.DataFrame()\n",
    "\n",
    "    # Get the list of files for the specified year\n",
    "    year_folder = str(year)\n",
    "\n",
    "    files = os.listdir(os.path.join(data_dir, year_folder))\n",
    "    \n",
    "    # Load data from each file in the folder\n",
    "    for filename in files:\n",
    "        if filename.endswith(\".csv\"):\n",
    "            # Read the CSV file\n",
    "            df = pd.read_csv(os.path.join(data_dir, year_folder, filename))\n",
    "            \n",
    "            # Add 'Year' and 'CropType' to the dataframe\n",
    "            base_name = filename.split('.')[0]\n",
    "            croptype = base_name.rsplit('202', 1)[0]  # Assuming the 'CropType' is before '202'\n",
    "            df['Year'] = year\n",
    "            df['CropType'] = croptype\n",
    "            \n",
    "            # Append to the main dataframe\n",
    "            data = pd.concat([data, df], ignore_index=True)\n",
    "    \n",
    "\n",
    "    return data\n",
    "# Process data for 2021, 2022, and 2023\n",
    "data_2021 = load_and_process_data(2021, data_dir)\n",
    "\n",
    "data_2022 = load_and_process_data(2022, data_dir)\n",
    "\n",
    "data_2023 = load_and_process_data(2023, data_dir)\n",
    "\n",
    "# Optionally, concatenate all years' data\n",
    "\n",
    "print(\"Data processing complete and saved to CSV files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NDVI01      0\n",
       "NDVI02      0\n",
       "NDVI03      0\n",
       "NDVI04      0\n",
       "NDVI05      0\n",
       "NDVI06      0\n",
       "NDVI07      0\n",
       "NDVI08      0\n",
       "NDVI09      0\n",
       "NDVI10      0\n",
       "NDVI11      0\n",
       "NDVI12      0\n",
       "Year        0\n",
       "CropType    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2021.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NDVI01      0\n",
       "NDVI02      0\n",
       "NDVI03      0\n",
       "NDVI04      0\n",
       "NDVI05      0\n",
       "NDVI06      0\n",
       "NDVI07      0\n",
       "NDVI08      0\n",
       "NDVI09      0\n",
       "NDVI10      0\n",
       "NDVI11      0\n",
       "NDVI12      0\n",
       "Year        0\n",
       "CropType    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2022.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NDVI01      0\n",
       "NDVI02      0\n",
       "NDVI03      0\n",
       "NDVI04      0\n",
       "NDVI05      0\n",
       "NDVI06      0\n",
       "NDVI07      0\n",
       "NDVI08      0\n",
       "NDVI09      0\n",
       "NDVI10      0\n",
       "NDVI11      0\n",
       "NDVI12      0\n",
       "Year        0\n",
       "CropType    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2023.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution: Counter({'cotton': 2883, 'rice': 419})\n",
      "Resampled class distribution: Counter({'cotton': 2883, 'rice': 2883})\n",
      "     NDVI01    NDVI02    NDVI03    NDVI04    NDVI05    NDVI06    NDVI07  \\\n",
      "0  0.048426  0.364378  1.313751  0.739004 -1.117934 -0.874930 -0.294260   \n",
      "1 -0.090054 -0.578735 -0.877894 -0.879544  0.735330 -0.247171  0.090724   \n",
      "2 -0.229702 -0.723652 -0.794634 -0.616548 -0.243985  0.420164  0.501506   \n",
      "3 -0.566691 -0.693198 -1.070449 -1.380114 -1.478248 -1.234065  0.098499   \n",
      "4 -0.508724 -0.673568 -0.356310 -0.664010  0.449389  1.108325  1.050623   \n",
      "\n",
      "     NDVI08    NDVI09    NDVI10    NDVI11    NDVI12 CropType  Year  \n",
      "0 -0.344886 -0.288542 -0.428172 -0.134149 -0.077385   cotton  2021  \n",
      "1  0.315508  0.505728  0.629748  0.412847  0.678032   cotton  2021  \n",
      "2  0.677059  0.777122  0.095502  0.449288  0.669009   cotton  2021  \n",
      "3  0.345676 -0.259112 -0.150463 -0.178729 -1.629277   cotton  2021  \n",
      "4  0.931262  0.372633  0.291644  0.300925  0.738062   cotton  2021  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import Counter\n",
    "\n",
    "# Assuming data_2021 is already loaded and processed\n",
    "# Separate features (X) and target variable (y)\n",
    "X = data_2021.drop(['CropType', 'Year'], axis=1)  # Exclude 'CropType' and 'Year' from features\n",
    "y = data_2021['CropType']  # Target variable ('CropType')\n",
    "year_column = data_2021['Year']  # Save the 'Year' column separately for later\n",
    "\n",
    "# Apply SMOTE to balance the classes\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Print original and resampled class distribution\n",
    "print(\"Original class distribution:\", Counter(y))\n",
    "print(\"Resampled class distribution:\", Counter(y_resampled))\n",
    "\n",
    "# Standardize the features (but exclude 'Year' and 'CropType' from scaling)\n",
    "scaler = StandardScaler()\n",
    "X_standardized = scaler.fit_transform(X_resampled)  # Apply scaling only to feature columns\n",
    "\n",
    "# Combine the standardized features with the target variable\n",
    "resampled_data_2021 = pd.DataFrame(X_standardized, columns=X.columns)\n",
    "resampled_data_2021['CropType'] = y_resampled\n",
    "\n",
    "# Reassign the 'Year' column to all rows as 2021 (since the resampled data comes from Year 2021)\n",
    "resampled_data_2021['Year'] = 2021  # Apply 2021 as the year for all resampled data\n",
    "\n",
    "# Preview the resampled dataset\n",
    "print(resampled_data_2021.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NDVI01      0\n",
       "NDVI02      0\n",
       "NDVI03      0\n",
       "NDVI04      0\n",
       "NDVI05      0\n",
       "NDVI06      0\n",
       "NDVI07      0\n",
       "NDVI08      0\n",
       "NDVI09      0\n",
       "NDVI10      0\n",
       "NDVI11      0\n",
       "NDVI12      0\n",
       "CropType    0\n",
       "Year        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resampled_data_2021.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution for 2022: Counter({'cotton': 12411, 'rice': 4687})\n",
      "Resampled class distribution for 2022: Counter({'cotton': 12411, 'rice': 12411})\n",
      "     NDVI01    NDVI02    NDVI03    NDVI04    NDVI05    NDVI06    NDVI07  \\\n",
      "0 -0.610981 -0.443648 -0.227025  0.414045  1.010668 -0.895838  0.736126   \n",
      "1 -0.218972  0.779917 -0.250334  0.098110  0.166561 -0.903439 -0.046474   \n",
      "2 -0.502855 -0.328901  0.451025  0.502992  0.172852 -0.620588  0.860952   \n",
      "3 -0.590039 -0.462387 -0.007411  0.216567 -0.038783 -0.768615  0.375152   \n",
      "4 -0.656842 -0.483838  0.252113  0.478944  0.566857 -0.787831 -0.027718   \n",
      "\n",
      "     NDVI08    NDVI09    NDVI10    NDVI11    NDVI12 CropType  Year  \n",
      "0 -0.346235 -0.161427 -0.483690 -0.298175 -1.183918   cotton  2022  \n",
      "1 -1.132150 -1.055036 -1.036662 -0.893418 -1.462894   cotton  2022  \n",
      "2 -0.070884  0.911934  0.344044  0.427055  0.351575   cotton  2022  \n",
      "3  0.043602  0.778235  0.380268  0.482109  0.260206   cotton  2022  \n",
      "4 -0.156893  0.720300  0.333902  0.482090  0.442770   cotton  2022  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import Counter\n",
    "\n",
    "# Assuming data_2022 is already loaded and processed for Year 2022\n",
    "# Separate features (X) and target variable (y)\n",
    "X_2022 = data_2022.drop(['CropType', 'Year'], axis=1)  # Exclude 'CropType' and 'Year' from features\n",
    "y_2022 = data_2022['CropType']  # Target variable ('CropType')\n",
    "year_column_2022 = data_2022['Year']  # Save the 'Year' column separately for later\n",
    "\n",
    "# Apply SMOTE to balance the classes\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_resampled_2022, y_resampled_2022 = smote.fit_resample(X_2022, y_2022)\n",
    "\n",
    "# Print original and resampled class distribution\n",
    "print(\"Original class distribution for 2022:\", Counter(y_2022))\n",
    "print(\"Resampled class distribution for 2022:\", Counter(y_resampled_2022))\n",
    "\n",
    "# Standardize the features (but exclude 'Year' and 'CropType' from scaling)\n",
    "scaler = StandardScaler()\n",
    "X_standardized_2022 = scaler.fit_transform(X_resampled_2022)  # Apply scaling only to feature columns\n",
    "\n",
    "# Combine the standardized features with the target variable\n",
    "resampled_data_2022 = pd.DataFrame(X_standardized_2022, columns=X_2022.columns)\n",
    "resampled_data_2022['CropType'] = y_resampled_2022\n",
    "\n",
    "# Reassign the 'Year' column to all rows as 2022 (since the resampled data comes from Year 2022)\n",
    "resampled_data_2022['Year'] = 2022  # Apply 2022 as the year for all resampled data\n",
    "\n",
    "# Preview the resampled dataset\n",
    "print(resampled_data_2022.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution for 2023: Counter({'cotton': 11777, 'rice': 919})\n",
      "Resampled class distribution for 2023: Counter({'cotton': 11777, 'rice': 11777})\n",
      "     NDVI01    NDVI02    NDVI03    NDVI04    NDVI05    NDVI06    NDVI07  \\\n",
      "0 -0.499531 -0.521506 -0.476625  0.104150 -0.847880 -1.126477  0.213996   \n",
      "1 -0.507457 -0.614468 -0.463191 -0.857633 -1.366655 -1.067575 -0.227343   \n",
      "2 -0.559412 -0.245671  0.276692  0.640592  0.398760 -1.064615  0.748825   \n",
      "3 -0.634009 -0.947978 -0.482678  0.928551  0.502002 -0.868699  0.854956   \n",
      "4 -0.574323 -0.957617 -0.588790  0.277204  0.029410 -0.558013  0.759989   \n",
      "\n",
      "     NDVI08    NDVI09    NDVI10    NDVI11    NDVI12 CropType  Year  \n",
      "0  0.714937  0.424402  0.260676 -0.028870 -1.718669   cotton  2023  \n",
      "1  0.320839  0.082033 -0.068685 -0.289261 -0.737127   cotton  2023  \n",
      "2  1.092430  0.875223  0.532995  0.344172  1.036608   cotton  2023  \n",
      "3  1.130121  0.851896  0.483806  0.210704  0.918104   cotton  2023  \n",
      "4  1.215590  0.861412  0.624981  0.290808  0.948156   cotton  2023  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import Counter\n",
    "\n",
    "# Assuming data_2023 is already loaded and processed for Year 2023\n",
    "# Separate features (X) and target variable (y)\n",
    "X_2023 = data_2023.drop(['CropType', 'Year'], axis=1)  # Exclude 'CropType' and 'Year' from features\n",
    "y_2023 = data_2023['CropType']  # Target variable ('CropType')\n",
    "year_column_2023 = data_2023['Year']  # Save the 'Year' column separately for later\n",
    "\n",
    "# Apply SMOTE to balance the classes\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_resampled_2023, y_resampled_2023 = smote.fit_resample(X_2023, y_2023)\n",
    "\n",
    "# Print original and resampled class distribution\n",
    "print(\"Original class distribution for 2023:\", Counter(y_2023))\n",
    "print(\"Resampled class distribution for 2023:\", Counter(y_resampled_2023))\n",
    "\n",
    "# Standardize the features (but exclude 'Year' and 'CropType' from scaling)\n",
    "scaler = StandardScaler()\n",
    "X_standardized_2023 = scaler.fit_transform(X_resampled_2023)  # Apply scaling only to feature columns\n",
    "\n",
    "# Combine the standardized features with the target variable\n",
    "resampled_data_2023 = pd.DataFrame(X_standardized_2023, columns=X_2023.columns)\n",
    "resampled_data_2023['CropType'] = y_resampled_2023\n",
    "\n",
    "# Reassign the 'Year' column to all rows as 2023 (since the resampled data comes from Year 2023)\n",
    "resampled_data_2023['Year'] = 2023  # Apply 2023 as the year for all resampled data\n",
    "\n",
    "# Preview the resampled dataset\n",
    "print(resampled_data_2023.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resampled_data_2023['Year'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     NDVI01    NDVI02    NDVI03    NDVI04    NDVI05    NDVI06    NDVI07  \\\n",
      "0  0.048426  0.364378  1.313751  0.739004 -1.117934 -0.874930 -0.294260   \n",
      "1 -0.090054 -0.578735 -0.877894 -0.879544  0.735330 -0.247171  0.090724   \n",
      "2 -0.229702 -0.723652 -0.794634 -0.616548 -0.243985  0.420164  0.501506   \n",
      "3 -0.566691 -0.693198 -1.070449 -1.380114 -1.478248 -1.234065  0.098499   \n",
      "4 -0.508724 -0.673568 -0.356310 -0.664010  0.449389  1.108325  1.050623   \n",
      "\n",
      "     NDVI08    NDVI09    NDVI10    NDVI11    NDVI12 CropType  Year  \n",
      "0 -0.344886 -0.288542 -0.428172 -0.134149 -0.077385   cotton  2021  \n",
      "1  0.315508  0.505728  0.629748  0.412847  0.678032   cotton  2021  \n",
      "2  0.677059  0.777122  0.095502  0.449288  0.669009   cotton  2021  \n",
      "3  0.345676 -0.259112 -0.150463 -0.178729 -1.629277   cotton  2021  \n",
      "4  0.931262  0.372633  0.291644  0.300925  0.738062   cotton  2021  \n"
     ]
    }
   ],
   "source": [
    "# Concatenate the three DataFrames (2021, 2022, and 2023) along the rows\n",
    "combined_data = pd.concat([resampled_data_2021,resampled_data_2022,resampled_data_2023], ignore_index=True)\n",
    "\n",
    "# Optional: Save the combined dataset to a CSV file\n",
    "combined_data.to_csv(\"combined_data_2021_2023.csv\", index=False)\n",
    "\n",
    "# Preview the combined dataset\n",
    "print(combined_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     NDVI01    NDVI02    NDVI03    NDVI04    NDVI05    NDVI06    NDVI07  \\\n",
      "0  0.048426  0.364378  1.313751  0.739004 -1.117934 -0.874930 -0.294260   \n",
      "1 -0.090054 -0.578735 -0.877894 -0.879544  0.735330 -0.247171  0.090724   \n",
      "2 -0.229702 -0.723652 -0.794634 -0.616548 -0.243985  0.420164  0.501506   \n",
      "3 -0.566691 -0.693198 -1.070449 -1.380114 -1.478248 -1.234065  0.098499   \n",
      "4 -0.508724 -0.673568 -0.356310 -0.664010  0.449389  1.108325  1.050623   \n",
      "\n",
      "     NDVI08    NDVI09    NDVI10    NDVI11    NDVI12  CropType  Year  \n",
      "0 -0.344886 -0.288542 -0.428172 -0.134149 -0.077385         1  2021  \n",
      "1  0.315508  0.505728  0.629748  0.412847  0.678032         1  2021  \n",
      "2  0.677059  0.777122  0.095502  0.449288  0.669009         1  2021  \n",
      "3  0.345676 -0.259112 -0.150463 -0.178729 -1.629277         1  2021  \n",
      "4  0.931262  0.372633  0.291644  0.300925  0.738062         1  2021  \n"
     ]
    }
   ],
   "source": [
    "# Assuming 'combined_data' contains the dataset\n",
    "# Convert 'CropType' into a binary column: 1 for 'cotton' and 0 for 'rice'\n",
    "combined_data['CropType'] = combined_data['CropType'].apply(lambda x: 1 if x == 'cotton' else 0)\n",
    "\n",
    "# Preview the updated DataFrame\n",
    "print(combined_data.head())\n",
    "\n",
    "# Optional: Save the updated dataset with one-hot encoded 'CropType' to a CSV file\n",
    "combined_data.to_csv(\"combined_data_one_hot_encoded.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 54142 entries, 0 to 54141\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   NDVI01    54142 non-null  float64\n",
      " 1   NDVI02    54142 non-null  float64\n",
      " 2   NDVI03    54142 non-null  float64\n",
      " 3   NDVI04    54142 non-null  float64\n",
      " 4   NDVI05    54142 non-null  float64\n",
      " 5   NDVI06    54142 non-null  float64\n",
      " 6   NDVI07    54142 non-null  float64\n",
      " 7   NDVI08    54142 non-null  float64\n",
      " 8   NDVI09    54142 non-null  float64\n",
      " 9   NDVI10    54142 non-null  float64\n",
      " 10  NDVI11    54142 non-null  float64\n",
      " 11  NDVI12    54142 non-null  float64\n",
      " 12  CropType  54142 non-null  int64  \n",
      " 13  Year      54142 non-null  int64  \n",
      "dtypes: float64(12), int64(2)\n",
      "memory usage: 5.8 MB\n"
     ]
    }
   ],
   "source": [
    "combined_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NDVI01</th>\n",
       "      <th>NDVI02</th>\n",
       "      <th>NDVI03</th>\n",
       "      <th>NDVI04</th>\n",
       "      <th>NDVI05</th>\n",
       "      <th>NDVI06</th>\n",
       "      <th>NDVI07</th>\n",
       "      <th>NDVI08</th>\n",
       "      <th>NDVI09</th>\n",
       "      <th>NDVI10</th>\n",
       "      <th>NDVI11</th>\n",
       "      <th>NDVI12</th>\n",
       "      <th>CropType</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54137</th>\n",
       "      <td>-0.276591</td>\n",
       "      <td>-0.659701</td>\n",
       "      <td>-1.202889</td>\n",
       "      <td>-1.648748</td>\n",
       "      <td>-2.572344</td>\n",
       "      <td>-0.716792</td>\n",
       "      <td>-0.320266</td>\n",
       "      <td>0.930492</td>\n",
       "      <td>1.038473</td>\n",
       "      <td>1.117808</td>\n",
       "      <td>1.148602</td>\n",
       "      <td>0.773826</td>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54138</th>\n",
       "      <td>-0.636423</td>\n",
       "      <td>0.833045</td>\n",
       "      <td>0.594123</td>\n",
       "      <td>0.343730</td>\n",
       "      <td>0.751864</td>\n",
       "      <td>-0.565845</td>\n",
       "      <td>-0.651761</td>\n",
       "      <td>-1.524006</td>\n",
       "      <td>-1.424529</td>\n",
       "      <td>-1.553073</td>\n",
       "      <td>-2.534672</td>\n",
       "      <td>-1.966206</td>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54139</th>\n",
       "      <td>-0.432611</td>\n",
       "      <td>-0.416944</td>\n",
       "      <td>-0.234195</td>\n",
       "      <td>0.468507</td>\n",
       "      <td>0.806384</td>\n",
       "      <td>1.287273</td>\n",
       "      <td>0.502616</td>\n",
       "      <td>-0.173280</td>\n",
       "      <td>-2.121937</td>\n",
       "      <td>-0.091659</td>\n",
       "      <td>0.987783</td>\n",
       "      <td>0.786822</td>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54140</th>\n",
       "      <td>-0.279345</td>\n",
       "      <td>1.042025</td>\n",
       "      <td>1.358211</td>\n",
       "      <td>0.969327</td>\n",
       "      <td>0.639725</td>\n",
       "      <td>0.891484</td>\n",
       "      <td>-1.827488</td>\n",
       "      <td>-0.610893</td>\n",
       "      <td>0.928919</td>\n",
       "      <td>0.939975</td>\n",
       "      <td>0.873468</td>\n",
       "      <td>0.540891</td>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54141</th>\n",
       "      <td>-0.401197</td>\n",
       "      <td>-0.549353</td>\n",
       "      <td>0.547258</td>\n",
       "      <td>1.102360</td>\n",
       "      <td>1.166258</td>\n",
       "      <td>1.495471</td>\n",
       "      <td>0.772204</td>\n",
       "      <td>0.181159</td>\n",
       "      <td>-2.265240</td>\n",
       "      <td>-0.073412</td>\n",
       "      <td>1.127242</td>\n",
       "      <td>0.526064</td>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         NDVI01    NDVI02    NDVI03    NDVI04    NDVI05    NDVI06    NDVI07  \\\n",
       "54137 -0.276591 -0.659701 -1.202889 -1.648748 -2.572344 -0.716792 -0.320266   \n",
       "54138 -0.636423  0.833045  0.594123  0.343730  0.751864 -0.565845 -0.651761   \n",
       "54139 -0.432611 -0.416944 -0.234195  0.468507  0.806384  1.287273  0.502616   \n",
       "54140 -0.279345  1.042025  1.358211  0.969327  0.639725  0.891484 -1.827488   \n",
       "54141 -0.401197 -0.549353  0.547258  1.102360  1.166258  1.495471  0.772204   \n",
       "\n",
       "         NDVI08    NDVI09    NDVI10    NDVI11    NDVI12  CropType  Year  \n",
       "54137  0.930492  1.038473  1.117808  1.148602  0.773826         0  2023  \n",
       "54138 -1.524006 -1.424529 -1.553073 -2.534672 -1.966206         0  2023  \n",
       "54139 -0.173280 -2.121937 -0.091659  0.987783  0.786822         0  2023  \n",
       "54140 -0.610893  0.928919  0.939975  0.873468  0.540891         0  2023  \n",
       "54141  0.181159 -2.265240 -0.073412  1.127242  0.526064         0  2023  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     NDVI01    NDVI02    NDVI03    NDVI04    NDVI05    NDVI06    NDVI07  \\\n",
      "0  0.048426  0.364378  1.313751  0.739004 -1.117934 -0.874930 -0.294260   \n",
      "1 -0.090054 -0.578735 -0.877894 -0.879544  0.735330 -0.247171  0.090724   \n",
      "2 -0.229702 -0.723652 -0.794634 -0.616548 -0.243985  0.420164  0.501506   \n",
      "3 -0.566691 -0.693198 -1.070449 -1.380114 -1.478248 -1.234065  0.098499   \n",
      "4 -0.508724 -0.673568 -0.356310 -0.664010  0.449389  1.108325  1.050623   \n",
      "\n",
      "     NDVI08    NDVI09    NDVI10    NDVI11    NDVI12  CropType  Year  \n",
      "0 -0.344886 -0.288542 -0.428172 -0.134149 -0.077385         1  2021  \n",
      "1  0.315508  0.505728  0.629748  0.412847  0.678032         1  2021  \n",
      "2  0.677059  0.777122  0.095502  0.449288  0.669009         1  2021  \n",
      "3  0.345676 -0.259112 -0.150463 -0.178729 -1.629277         1  2021  \n",
      "4  0.931262  0.372633  0.291644  0.300925  0.738062         1  2021  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Separate features (X) and the target ('CropType') and 'Year' column (to keep unchanged)\n",
    "X = combined_data.drop(['CropType', 'Year'], axis=1)  # Exclude 'CropType' and 'Year' from features\n",
    "y = combined_data['CropType']  # Target variable ('CropType')\n",
    "year_column = combined_data['Year']  # 'Year' column remains unchanged\n",
    "\n",
    "# Apply StandardScaler to the feature columns\n",
    "scaler = StandardScaler()\n",
    "X_standardized = scaler.fit_transform(X)\n",
    "\n",
    "# Combine the standardized features back with the target variable and 'Year' column\n",
    "standardized_data = pd.DataFrame(X_standardized, columns=X.columns)\n",
    "standardized_data['CropType'] = y\n",
    "standardized_data['Year'] = year_column  # Keep 'Year' column unchanged\n",
    "\n",
    "# Preview the standardized dataset\n",
    "print(standardized_data.head())\n",
    "\n",
    "# Optional: Save the standardized dataset to a CSV file\n",
    "standardized_data.to_csv(\"standardized_combined_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Train: Year 1 & 2, Test: Year 3): 0.7309161925787552\n",
      "Classification Report for (Train: Year 1 & 2, Test: Year 3):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.74      0.73     11777\n",
      "           1       0.73      0.73      0.73     11777\n",
      "\n",
      "    accuracy                           0.73     23554\n",
      "   macro avg       0.73      0.73      0.73     23554\n",
      "weighted avg       0.73      0.73      0.73     23554\n",
      "\n",
      "\n",
      "Accuracy (Train: Year 1 & 3, Test: Year 2): 0.5736040609137056\n",
      "Classification Report for (Train: Year 1 & 3, Test: Year 2):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.54      0.56     12411\n",
      "           1       0.57      0.61      0.59     12411\n",
      "\n",
      "    accuracy                           0.57     24822\n",
      "   macro avg       0.57      0.57      0.57     24822\n",
      "weighted avg       0.57      0.57      0.57     24822\n",
      "\n",
      "\n",
      "Accuracy (Train: Year 2 & 3, Test: Year 1): 0.6807145334720777\n",
      "Classification Report for (Train: Year 2 & 3, Test: Year 1):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.63      0.66      2883\n",
      "           1       0.66      0.73      0.70      2883\n",
      "\n",
      "    accuracy                           0.68      5766\n",
      "   macro avg       0.68      0.68      0.68      5766\n",
      "weighted avg       0.68      0.68      0.68      5766\n",
      "\n",
      "\n",
      "Overall Metrics:\n",
      "Overall Accuracy: 0.6534\n",
      "Overall Precision: 0.6481\n",
      "Overall Recall: 0.6715\n",
      "Overall F1-Score: 0.6596\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Separate the features (X) and target variable (y)\n",
    "X = standardized_data.drop(['CropType', 'Year'], axis=1)  # Exclude 'CropType' and 'Year' from features\n",
    "y = standardized_data['CropType']  # Target variable ('CropType')\n",
    "\n",
    "# Function to perform cross-validation with the specified combinations\n",
    "def cross_validation_logistic_regression(X, y):\n",
    "    # Initialize a Logistic Regression model\n",
    "    model = LogisticRegression(random_state=42)\n",
    "\n",
    "    # Create lists to store results for overall metrics\n",
    "    all_y_true = []  # List to hold true labels across all folds\n",
    "    all_y_pred = []  # List to hold predicted labels across all folds\n",
    "\n",
    "    # 1. Train on Year 1 and Year 2, Test on Year 3\n",
    "    train_data_1_2 = standardized_data[standardized_data['Year'].isin([2021, 2022])]\n",
    "    test_data_3 = standardized_data[standardized_data['Year'] == 2023]\n",
    "    \n",
    "    X_train_1_2 = train_data_1_2.drop(['CropType', 'Year'], axis=1)\n",
    "    y_train_1_2 = train_data_1_2['CropType']\n",
    "    X_test_3 = test_data_3.drop(['CropType', 'Year'], axis=1)\n",
    "    y_test_3 = test_data_3['CropType']\n",
    "    \n",
    "    # Train the model and evaluate\n",
    "    model.fit(X_train_1_2, y_train_1_2)\n",
    "    y_pred_3 = model.predict(X_test_3)\n",
    "    \n",
    "    accuracy_1_2_vs_3 = accuracy_score(y_test_3, y_pred_3)\n",
    "    print(\"Accuracy (Train: Year 1 & 2, Test: Year 3):\", accuracy_1_2_vs_3)\n",
    "    print(\"Classification Report for (Train: Year 1 & 2, Test: Year 3):\\n\", classification_report(y_test_3, y_pred_3))\n",
    "    \n",
    "    # Append results to lists for overall metrics\n",
    "    all_y_true.extend(y_test_3)\n",
    "    all_y_pred.extend(y_pred_3)\n",
    "\n",
    "    # Second combination: Train on Year 1 (2021) and Year 3 (2023), Test on Year 2 (2022)\n",
    "    train_data_1_3 = standardized_data[standardized_data['Year'].isin([2021, 2023])]\n",
    "    test_data_2 = standardized_data[standardized_data['Year'] == 2022]\n",
    "    \n",
    "    X_train_1_3 = train_data_1_3.drop(['CropType', 'Year'], axis=1)\n",
    "    y_train_1_3 = train_data_1_3['CropType']\n",
    "    X_test_2 = test_data_2.drop(['CropType', 'Year'], axis=1)\n",
    "    y_test_2 = test_data_2['CropType']\n",
    "    \n",
    "    # Train the model and evaluate\n",
    "    model.fit(X_train_1_3, y_train_1_3)\n",
    "    y_pred_2 = model.predict(X_test_2)\n",
    "    \n",
    "    accuracy_1_3_vs_2 = accuracy_score(y_test_2, y_pred_2)\n",
    "    print(\"\\nAccuracy (Train: Year 1 & 3, Test: Year 2):\", accuracy_1_3_vs_2)\n",
    "    print(\"Classification Report for (Train: Year 1 & 3, Test: Year 2):\\n\", classification_report(y_test_2, y_pred_2))\n",
    "    \n",
    "    # Append results to lists for overall metrics\n",
    "    all_y_true.extend(y_test_2)\n",
    "    all_y_pred.extend(y_pred_2)\n",
    "\n",
    "    # Third combination: Train on Year 2 (2022) and Year 3 (2023), Test on Year 1 (2021)\n",
    "    train_data_2_3 = standardized_data[standardized_data['Year'].isin([2022, 2023])]\n",
    "    test_data_1 = standardized_data[standardized_data['Year'] == 2021]\n",
    "    \n",
    "    X_train_2_3 = train_data_2_3.drop(['CropType', 'Year'], axis=1)\n",
    "    y_train_2_3 = train_data_2_3['CropType']\n",
    "    X_test_1 = test_data_1.drop(['CropType', 'Year'], axis=1)\n",
    "    y_test_1 = test_data_1['CropType']\n",
    "    \n",
    "    # Train the model and evaluate\n",
    "    model.fit(X_train_2_3, y_train_2_3)\n",
    "    y_pred_1 = model.predict(X_test_1)\n",
    "    \n",
    "    accuracy_2_3_vs_1 = accuracy_score(y_test_1, y_pred_1)\n",
    "    print(\"\\nAccuracy (Train: Year 2 & 3, Test: Year 1):\", accuracy_2_3_vs_1)\n",
    "    print(\"Classification Report for (Train: Year 2 & 3, Test: Year 1):\\n\", classification_report(y_test_1, y_pred_1))\n",
    "    \n",
    "    # Append results to lists for overall metrics\n",
    "    all_y_true.extend(y_test_1)\n",
    "    all_y_pred.extend(y_pred_1)\n",
    "\n",
    "    # Calculate overall metrics\n",
    "    overall_accuracy = accuracy_score(all_y_true, all_y_pred)\n",
    "    overall_precision = precision_score(all_y_true, all_y_pred)\n",
    "    overall_recall = recall_score(all_y_true, all_y_pred)\n",
    "    overall_f1 = f1_score(all_y_true, all_y_pred)\n",
    "\n",
    "    print(\"\\nOverall Metrics:\")\n",
    "    print(f\"Overall Accuracy: {overall_accuracy:.4f}\")\n",
    "    print(f\"Overall Precision: {overall_precision:.4f}\")\n",
    "    print(f\"Overall Recall: {overall_recall:.4f}\")\n",
    "    print(f\"Overall F1-Score: {overall_f1:.4f}\")\n",
    "\n",
    "# Call the function to perform cross-validation and logistic regression\n",
    "cross_validation_logistic_regression(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarma\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\core.py:158: UserWarning: [16:34:10] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Train: Year 1 & 2, Test: Year 3): 0.8369703659675639\n",
      "Classification Report for (Train: Year 1 & 2, Test: Year 3):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.78      0.83     11777\n",
      "           1       0.80      0.90      0.85     11777\n",
      "\n",
      "    accuracy                           0.84     23554\n",
      "   macro avg       0.84      0.84      0.84     23554\n",
      "weighted avg       0.84      0.84      0.84     23554\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarma\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\core.py:158: UserWarning: [16:34:10] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy (Train: Year 1 & 3, Test: Year 2): 0.6785109983079526\n",
      "Classification Report for (Train: Year 1 & 3, Test: Year 2):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.42      0.57     12411\n",
      "           1       0.62      0.93      0.74     12411\n",
      "\n",
      "    accuracy                           0.68     24822\n",
      "   macro avg       0.74      0.68      0.66     24822\n",
      "weighted avg       0.74      0.68      0.66     24822\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarma\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\core.py:158: UserWarning: [16:34:11] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy (Train: Year 2 & 3, Test: Year 1): 0.7660423170308707\n",
      "Classification Report for (Train: Year 2 & 3, Test: Year 1):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.65      0.74      2883\n",
      "           1       0.72      0.88      0.79      2883\n",
      "\n",
      "    accuracy                           0.77      5766\n",
      "   macro avg       0.78      0.77      0.76      5766\n",
      "weighted avg       0.78      0.77      0.76      5766\n",
      "\n",
      "\n",
      "Overall Metrics:\n",
      "Overall Accuracy: 0.7568\n",
      "Overall Precision: 0.7839\n",
      "Overall Recall: 0.7568\n",
      "Overall F1-Score: 0.7508\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Separate the features (X) and target variable (y)\n",
    "X = standardized_data.drop(['CropType', 'Year'], axis=1)  # Exclude 'CropType' and 'Year' from features\n",
    "y = standardized_data['CropType']  # Target variable ('CropType')\n",
    "\n",
    "# Function to perform cross-validation with the specified combinations using XGBoost\n",
    "def cross_validation_xgboost(X, y):\n",
    "    # Initialize an XGBoost model\n",
    "    model = xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss')\n",
    "\n",
    "    # Create lists to store results for overall metrics\n",
    "    all_y_true = []  # List to hold true labels across all folds\n",
    "    all_y_pred = []  # List to hold predicted labels across all folds\n",
    "\n",
    "    # 1. Train on Year 1 and Year 2, Test on Year 3\n",
    "    train_data_1_2 = standardized_data[standardized_data['Year'].isin([2021, 2022])]\n",
    "    test_data_3 = standardized_data[standardized_data['Year'] == 2023]\n",
    "    \n",
    "    X_train_1_2 = train_data_1_2.drop(['CropType', 'Year'], axis=1)\n",
    "    y_train_1_2 = train_data_1_2['CropType']\n",
    "    X_test_3 = test_data_3.drop(['CropType', 'Year'], axis=1)\n",
    "    y_test_3 = test_data_3['CropType']\n",
    "    \n",
    "    # Train the model and evaluate\n",
    "    model.fit(X_train_1_2, y_train_1_2)\n",
    "    y_pred_3 = model.predict(X_test_3)\n",
    "    \n",
    "    accuracy_1_2_vs_3 = accuracy_score(y_test_3, y_pred_3)\n",
    "    print(\"Accuracy (Train: Year 1 & 2, Test: Year 3):\", accuracy_1_2_vs_3)\n",
    "    print(\"Classification Report for (Train: Year 1 & 2, Test: Year 3):\\n\", classification_report(y_test_3, y_pred_3))\n",
    "    \n",
    "    # Append results to lists for overall metrics\n",
    "    all_y_true.extend(y_test_3)\n",
    "    all_y_pred.extend(y_pred_3)\n",
    "\n",
    "    # Second combination: Train on Year 1 (2021) and Year 3 (2023), Test on Year 2 (2022)\n",
    "    train_data_1_3 = standardized_data[standardized_data['Year'].isin([2021, 2023])]\n",
    "    test_data_2 = standardized_data[standardized_data['Year'] == 2022]\n",
    "    \n",
    "    X_train_1_3 = train_data_1_3.drop(['CropType', 'Year'], axis=1)\n",
    "    y_train_1_3 = train_data_1_3['CropType']\n",
    "    X_test_2 = test_data_2.drop(['CropType', 'Year'], axis=1)\n",
    "    y_test_2 = test_data_2['CropType']\n",
    "    \n",
    "    # Train the model and evaluate\n",
    "    model.fit(X_train_1_3, y_train_1_3)\n",
    "    y_pred_2 = model.predict(X_test_2)\n",
    "    \n",
    "    accuracy_1_3_vs_2 = accuracy_score(y_test_2, y_pred_2)\n",
    "    print(\"\\nAccuracy (Train: Year 1 & 3, Test: Year 2):\", accuracy_1_3_vs_2)\n",
    "    print(\"Classification Report for (Train: Year 1 & 3, Test: Year 2):\\n\", classification_report(y_test_2, y_pred_2))\n",
    "    \n",
    "    # Append results to lists for overall metrics\n",
    "    all_y_true.extend(y_test_2)\n",
    "    all_y_pred.extend(y_pred_2)\n",
    "\n",
    "    # Third combination: Train on Year 2 (2022) and Year 3 (2023), Test on Year 1 (2021)\n",
    "    train_data_2_3 = standardized_data[standardized_data['Year'].isin([2022, 2023])]\n",
    "    test_data_1 = standardized_data[standardized_data['Year'] == 2021]\n",
    "    \n",
    "    X_train_2_3 = train_data_2_3.drop(['CropType', 'Year'], axis=1)\n",
    "    y_train_2_3 = train_data_2_3['CropType']\n",
    "    X_test_1 = test_data_1.drop(['CropType', 'Year'], axis=1)\n",
    "    y_test_1 = test_data_1['CropType']\n",
    "    \n",
    "    # Train the model and evaluate\n",
    "    model.fit(X_train_2_3, y_train_2_3)\n",
    "    y_pred_1 = model.predict(X_test_1)\n",
    "    \n",
    "    accuracy_2_3_vs_1 = accuracy_score(y_test_1, y_pred_1)\n",
    "    print(\"\\nAccuracy (Train: Year 2 & 3, Test: Year 1):\", accuracy_2_3_vs_1)\n",
    "    print(\"Classification Report for (Train: Year 2 & 3, Test: Year 1):\\n\", classification_report(y_test_1, y_pred_1))\n",
    "    \n",
    "    # Append results to lists for overall metrics\n",
    "    all_y_true.extend(y_test_1)\n",
    "    all_y_pred.extend(y_pred_1)\n",
    "\n",
    "    # Calculate overall metrics\n",
    "    overall_accuracy = accuracy_score(all_y_true, all_y_pred)\n",
    "    overall_precision = precision_score(all_y_true, all_y_pred, average='weighted')\n",
    "    overall_recall = recall_score(all_y_true, all_y_pred, average='weighted')\n",
    "    overall_f1 = f1_score(all_y_true, all_y_pred, average='weighted')\n",
    "\n",
    "    print(\"\\nOverall Metrics:\")\n",
    "    print(f\"Overall Accuracy: {overall_accuracy:.4f}\")\n",
    "    print(f\"Overall Precision: {overall_precision:.4f}\")\n",
    "    print(f\"Overall Recall: {overall_recall:.4f}\")\n",
    "    print(f\"Overall F1-Score: {overall_f1:.4f}\")\n",
    "\n",
    "# Call the function to perform cross-validation and XGBoost\n",
    "cross_validation_xgboost(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarma\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Train: Year 1 & 2, Test: Year 3): 0.824658232147406\n",
      "Classification Report for (Train: Year 1 & 2, Test: Year 3):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.78      0.82     11777\n",
      "           1       0.80      0.87      0.83     11777\n",
      "\n",
      "    accuracy                           0.82     23554\n",
      "   macro avg       0.83      0.82      0.82     23554\n",
      "weighted avg       0.83      0.82      0.82     23554\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarma\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy (Train: Year 1 & 3, Test: Year 2): 0.6739182982837805\n",
      "Classification Report for (Train: Year 1 & 3, Test: Year 2):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.43      0.57     12411\n",
      "           1       0.62      0.92      0.74     12411\n",
      "\n",
      "    accuracy                           0.67     24822\n",
      "   macro avg       0.73      0.67      0.65     24822\n",
      "weighted avg       0.73      0.67      0.65     24822\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarma\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy (Train: Year 2 & 3, Test: Year 1): 0.7584113770378078\n",
      "Classification Report for (Train: Year 2 & 3, Test: Year 1):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.62      0.72      2883\n",
      "           1       0.70      0.90      0.79      2883\n",
      "\n",
      "    accuracy                           0.76      5766\n",
      "   macro avg       0.78      0.76      0.75      5766\n",
      "weighted avg       0.78      0.76      0.75      5766\n",
      "\n",
      "\n",
      "Overall Metrics:\n",
      "Overall Accuracy: 0.7485\n",
      "Overall Precision: 0.7721\n",
      "Overall Recall: 0.7485\n",
      "Overall F1-Score: 0.7429\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Separate the features (X) and target variable (y)\n",
    "X = standardized_data.drop(['CropType', 'Year'], axis=1)  # Exclude 'CropType' and 'Year' from features\n",
    "y = standardized_data['CropType']  # Target variable ('CropType')\n",
    "\n",
    "# Function to perform cross-validation with the specified combinations using Bagging Classifier\n",
    "def cross_validation_bagging(X, y):\n",
    "    # Initialize a DecisionTreeClassifier as the base model for Bagging\n",
    "    base_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "    # Initialize the BaggingClassifier with the DecisionTree as the base model\n",
    "    model = BaggingClassifier(base_estimator=base_model, n_estimators=50, random_state=42)\n",
    "\n",
    "    # Create lists to store results for overall metrics\n",
    "    all_y_true = []  # List to hold true labels across all folds\n",
    "    all_y_pred = []  # List to hold predicted labels across all folds\n",
    "\n",
    "    # 1. Train on Year 1 and Year 2, Test on Year 3\n",
    "    train_data_1_2 = standardized_data[standardized_data['Year'].isin([2021, 2022])]\n",
    "    test_data_3 = standardized_data[standardized_data['Year'] == 2023]\n",
    "    \n",
    "    X_train_1_2 = train_data_1_2.drop(['CropType', 'Year'], axis=1)\n",
    "    y_train_1_2 = train_data_1_2['CropType']\n",
    "    X_test_3 = test_data_3.drop(['CropType', 'Year'], axis=1)\n",
    "    y_test_3 = test_data_3['CropType']\n",
    "    \n",
    "    # Train the model and evaluate\n",
    "    model.fit(X_train_1_2, y_train_1_2)\n",
    "    y_pred_3 = model.predict(X_test_3)\n",
    "    \n",
    "    accuracy_1_2_vs_3 = accuracy_score(y_test_3, y_pred_3)\n",
    "    print(\"Accuracy (Train: Year 1 & 2, Test: Year 3):\", accuracy_1_2_vs_3)\n",
    "    print(\"Classification Report for (Train: Year 1 & 2, Test: Year 3):\\n\", classification_report(y_test_3, y_pred_3))\n",
    "    \n",
    "    # Append results to lists for overall metrics\n",
    "    all_y_true.extend(y_test_3)\n",
    "    all_y_pred.extend(y_pred_3)\n",
    "\n",
    "    # Second combination: Train on Year 1 (2021) and Year 3 (2023), Test on Year 2 (2022)\n",
    "    train_data_1_3 = standardized_data[standardized_data['Year'].isin([2021, 2023])]\n",
    "    test_data_2 = standardized_data[standardized_data['Year'] == 2022]\n",
    "    \n",
    "    X_train_1_3 = train_data_1_3.drop(['CropType', 'Year'], axis=1)\n",
    "    y_train_1_3 = train_data_1_3['CropType']\n",
    "    X_test_2 = test_data_2.drop(['CropType', 'Year'], axis=1)\n",
    "    y_test_2 = test_data_2['CropType']\n",
    "    \n",
    "    # Train the model and evaluate\n",
    "    model.fit(X_train_1_3, y_train_1_3)\n",
    "    y_pred_2 = model.predict(X_test_2)\n",
    "    \n",
    "    accuracy_1_3_vs_2 = accuracy_score(y_test_2, y_pred_2)\n",
    "    print(\"\\nAccuracy (Train: Year 1 & 3, Test: Year 2):\", accuracy_1_3_vs_2)\n",
    "    print(\"Classification Report for (Train: Year 1 & 3, Test: Year 2):\\n\", classification_report(y_test_2, y_pred_2))\n",
    "    \n",
    "    # Append results to lists for overall metrics\n",
    "    all_y_true.extend(y_test_2)\n",
    "    all_y_pred.extend(y_pred_2)\n",
    "\n",
    "    # Third combination: Train on Year 2 (2022) and Year 3 (2023), Test on Year 1 (2021)\n",
    "    train_data_2_3 = standardized_data[standardized_data['Year'].isin([2022, 2023])]\n",
    "    test_data_1 = standardized_data[standardized_data['Year'] == 2021]\n",
    "    \n",
    "    X_train_2_3 = train_data_2_3.drop(['CropType', 'Year'], axis=1)\n",
    "    y_train_2_3 = train_data_2_3['CropType']\n",
    "    X_test_1 = test_data_1.drop(['CropType', 'Year'], axis=1)\n",
    "    y_test_1 = test_data_1['CropType']\n",
    "    \n",
    "    # Train the model and evaluate\n",
    "    model.fit(X_train_2_3, y_train_2_3)\n",
    "    y_pred_1 = model.predict(X_test_1)\n",
    "    \n",
    "    accuracy_2_3_vs_1 = accuracy_score(y_test_1, y_pred_1)\n",
    "    print(\"\\nAccuracy (Train: Year 2 & 3, Test: Year 1):\", accuracy_2_3_vs_1)\n",
    "    print(\"Classification Report for (Train: Year 2 & 3, Test: Year 1):\\n\", classification_report(y_test_1, y_pred_1))\n",
    "    \n",
    "    # Append results to lists for overall metrics\n",
    "    all_y_true.extend(y_test_1)\n",
    "    all_y_pred.extend(y_pred_1)\n",
    "\n",
    "    # Calculate overall metrics\n",
    "    overall_accuracy = accuracy_score(all_y_true, all_y_pred)\n",
    "    overall_precision = precision_score(all_y_true, all_y_pred, average='weighted')\n",
    "    overall_recall = recall_score(all_y_true, all_y_pred, average='weighted')\n",
    "    overall_f1 = f1_score(all_y_true, all_y_pred, average='weighted')\n",
    "\n",
    "    print(\"\\nOverall Metrics:\")\n",
    "    print(f\"Overall Accuracy: {overall_accuracy:.4f}\")\n",
    "    print(f\"Overall Precision: {overall_precision:.4f}\")\n",
    "    print(f\"Overall Recall: {overall_recall:.4f}\")\n",
    "    print(f\"Overall F1-Score: {overall_f1:.4f}\")\n",
    "\n",
    "# Call the function to perform cross-validation and Bagging Classifier\n",
    "cross_validation_bagging(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Train: Year 1 & 2, Test: Year 3): 0.855863123036427\n",
      "Classification Report for (Train: Year 1 & 2, Test: Year 3):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.81      0.85     11777\n",
      "           1       0.82      0.90      0.86     11777\n",
      "\n",
      "    accuracy                           0.86     23554\n",
      "   macro avg       0.86      0.86      0.86     23554\n",
      "weighted avg       0.86      0.86      0.86     23554\n",
      "\n",
      "\n",
      "Accuracy (Train: Year 1 & 3, Test: Year 2): 0.6609862218999275\n",
      "Classification Report for (Train: Year 1 & 3, Test: Year 2):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.37      0.52     12411\n",
      "           1       0.60      0.95      0.74     12411\n",
      "\n",
      "    accuracy                           0.66     24822\n",
      "   macro avg       0.74      0.66      0.63     24822\n",
      "weighted avg       0.74      0.66      0.63     24822\n",
      "\n",
      "\n",
      "Accuracy (Train: Year 2 & 3, Test: Year 1): 0.7787027402011794\n",
      "Classification Report for (Train: Year 2 & 3, Test: Year 1):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.64      0.74      2883\n",
      "           1       0.72      0.91      0.80      2883\n",
      "\n",
      "    accuracy                           0.78      5766\n",
      "   macro avg       0.80      0.78      0.77      5766\n",
      "weighted avg       0.80      0.78      0.77      5766\n",
      "\n",
      "\n",
      "Overall Metrics:\n",
      "Overall Accuracy: 0.7583\n",
      "Overall Precision: 0.7908\n",
      "Overall Recall: 0.7583\n",
      "Overall F1-Score: 0.7514\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Separate the features (X) and target variable (y)\n",
    "X = standardized_data.drop(['CropType', 'Year'], axis=1)  # Exclude 'CropType' and 'Year' from features\n",
    "y = standardized_data['CropType']  # Target variable ('CropType')\n",
    "\n",
    "# Function to perform cross-validation with the specified combinations using Random Forest Classifier\n",
    "def cross_validation_random_forest(X, y):\n",
    "    # Initialize the RandomForestClassifier\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "    # Create lists to store results for overall metrics\n",
    "    all_y_true = []  # List to hold true labels across all folds\n",
    "    all_y_pred = []  # List to hold predicted labels across all folds\n",
    "\n",
    "    # 1. Train on Year 1 and Year 2, Test on Year 3\n",
    "    train_data_1_2 = standardized_data[standardized_data['Year'].isin([2021, 2022])]\n",
    "    test_data_3 = standardized_data[standardized_data['Year'] == 2023]\n",
    "    \n",
    "    X_train_1_2 = train_data_1_2.drop(['CropType', 'Year'], axis=1)\n",
    "    y_train_1_2 = train_data_1_2['CropType']\n",
    "    X_test_3 = test_data_3.drop(['CropType', 'Year'], axis=1)\n",
    "    y_test_3 = test_data_3['CropType']\n",
    "    \n",
    "    # Train the model and evaluate\n",
    "    model.fit(X_train_1_2, y_train_1_2)\n",
    "    y_pred_3 = model.predict(X_test_3)\n",
    "    \n",
    "    accuracy_1_2_vs_3 = accuracy_score(y_test_3, y_pred_3)\n",
    "    print(\"Accuracy (Train: Year 1 & 2, Test: Year 3):\", accuracy_1_2_vs_3)\n",
    "    print(\"Classification Report for (Train: Year 1 & 2, Test: Year 3):\\n\", classification_report(y_test_3, y_pred_3))\n",
    "    \n",
    "    # Append results to lists for overall metrics\n",
    "    all_y_true.extend(y_test_3)\n",
    "    all_y_pred.extend(y_pred_3)\n",
    "\n",
    "    # Second combination: Train on Year 1 (2021) and Year 3 (2023), Test on Year 2 (2022)\n",
    "    train_data_1_3 = standardized_data[standardized_data['Year'].isin([2021, 2023])]\n",
    "    test_data_2 = standardized_data[standardized_data['Year'] == 2022]\n",
    "    \n",
    "    X_train_1_3 = train_data_1_3.drop(['CropType', 'Year'], axis=1)\n",
    "    y_train_1_3 = train_data_1_3['CropType']\n",
    "    X_test_2 = test_data_2.drop(['CropType', 'Year'], axis=1)\n",
    "    y_test_2 = test_data_2['CropType']\n",
    "    \n",
    "    # Train the model and evaluate\n",
    "    model.fit(X_train_1_3, y_train_1_3)\n",
    "    y_pred_2 = model.predict(X_test_2)\n",
    "    \n",
    "    accuracy_1_3_vs_2 = accuracy_score(y_test_2, y_pred_2)\n",
    "    print(\"\\nAccuracy (Train: Year 1 & 3, Test: Year 2):\", accuracy_1_3_vs_2)\n",
    "    print(\"Classification Report for (Train: Year 1 & 3, Test: Year 2):\\n\", classification_report(y_test_2, y_pred_2))\n",
    "    \n",
    "    # Append results to lists for overall metrics\n",
    "    all_y_true.extend(y_test_2)\n",
    "    all_y_pred.extend(y_pred_2)\n",
    "\n",
    "    # Third combination: Train on Year 2 (2022) and Year 3 (2023), Test on Year 1 (2021)\n",
    "    train_data_2_3 = standardized_data[standardized_data['Year'].isin([2022, 2023])]\n",
    "    test_data_1 = standardized_data[standardized_data['Year'] == 2021]\n",
    "    \n",
    "    X_train_2_3 = train_data_2_3.drop(['CropType', 'Year'], axis=1)\n",
    "    y_train_2_3 = train_data_2_3['CropType']\n",
    "    X_test_1 = test_data_1.drop(['CropType', 'Year'], axis=1)\n",
    "    y_test_1 = test_data_1['CropType']\n",
    "    \n",
    "    # Train the model and evaluate\n",
    "    model.fit(X_train_2_3, y_train_2_3)\n",
    "    y_pred_1 = model.predict(X_test_1)\n",
    "    \n",
    "    accuracy_2_3_vs_1 = accuracy_score(y_test_1, y_pred_1)\n",
    "    print(\"\\nAccuracy (Train: Year 2 & 3, Test: Year 1):\", accuracy_2_3_vs_1)\n",
    "    print(\"Classification Report for (Train: Year 2 & 3, Test: Year 1):\\n\", classification_report(y_test_1, y_pred_1))\n",
    "    \n",
    "    # Append results to lists for overall metrics\n",
    "    all_y_true.extend(y_test_1)\n",
    "    all_y_pred.extend(y_pred_1)\n",
    "\n",
    "    # Calculate overall metrics\n",
    "    overall_accuracy = accuracy_score(all_y_true, all_y_pred)\n",
    "    overall_precision = precision_score(all_y_true, all_y_pred, average='weighted')\n",
    "    overall_recall = recall_score(all_y_true, all_y_pred, average='weighted')\n",
    "    overall_f1 = f1_score(all_y_true, all_y_pred, average='weighted')\n",
    "\n",
    "    print(\"\\nOverall Metrics:\")\n",
    "    print(f\"Overall Accuracy: {overall_accuracy:.4f}\")\n",
    "    print(f\"Overall Precision: {overall_precision:.4f}\")\n",
    "    print(f\"Overall Recall: {overall_recall:.4f}\")\n",
    "    print(f\"Overall F1-Score: {overall_f1:.4f}\")\n",
    "\n",
    "# Call the function to perform cross-validation and Random Forest Classifier\n",
    "cross_validation_random_forest(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Train: Year 1 & 2, Test: Year 3): 0.7532054003566273\n",
      "Classification Report for (Train: Year 1 & 2, Test: Year 3):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.69      0.74     11777\n",
      "           1       0.73      0.81      0.77     11777\n",
      "\n",
      "    accuracy                           0.75     23554\n",
      "   macro avg       0.76      0.75      0.75     23554\n",
      "weighted avg       0.76      0.75      0.75     23554\n",
      "\n",
      "\n",
      "Accuracy (Train: Year 1 & 3, Test: Year 2): 0.5845217951816937\n",
      "Classification Report for (Train: Year 1 & 3, Test: Year 2):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.51      0.55     12411\n",
      "           1       0.57      0.66      0.61     12411\n",
      "\n",
      "    accuracy                           0.58     24822\n",
      "   macro avg       0.59      0.58      0.58     24822\n",
      "weighted avg       0.59      0.58      0.58     24822\n",
      "\n",
      "\n",
      "Accuracy (Train: Year 2 & 3, Test: Year 1): 0.7771418661116892\n",
      "Classification Report for (Train: Year 2 & 3, Test: Year 1):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.65      0.74      2883\n",
      "           1       0.72      0.91      0.80      2883\n",
      "\n",
      "    accuracy                           0.78      5766\n",
      "   macro avg       0.80      0.78      0.77      5766\n",
      "weighted avg       0.80      0.78      0.77      5766\n",
      "\n",
      "\n",
      "Overall Metrics:\n",
      "Overall Accuracy: 0.6784\n",
      "Overall Precision: 0.6824\n",
      "Overall Recall: 0.6784\n",
      "Overall F1-Score: 0.6767\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Separate the features (X) and target variable (y)\n",
    "X = standardized_data.drop(['CropType', 'Year'], axis=1)  # Exclude 'CropType' and 'Year' from features\n",
    "y = standardized_data['CropType']  # Target variable ('CropType')\n",
    "\n",
    "# Function to perform cross-validation with the specified combinations using Naive Bayes\n",
    "def cross_validation_naive_bayes(X, y):\n",
    "    # Initialize the Gaussian Naive Bayes model\n",
    "    model = GaussianNB()\n",
    "\n",
    "    # Create lists to store results for overall metrics\n",
    "    all_y_true = []  # List to hold true labels across all folds\n",
    "    all_y_pred = []  # List to hold predicted labels across all folds\n",
    "\n",
    "    # 1. Train on Year 1 and Year 2, Test on Year 3\n",
    "    train_data_1_2 = standardized_data[standardized_data['Year'].isin([2021, 2022])]\n",
    "    test_data_3 = standardized_data[standardized_data['Year'] == 2023]\n",
    "    \n",
    "    X_train_1_2 = train_data_1_2.drop(['CropType', 'Year'], axis=1)\n",
    "    y_train_1_2 = train_data_1_2['CropType']\n",
    "    X_test_3 = test_data_3.drop(['CropType', 'Year'], axis=1)\n",
    "    y_test_3 = test_data_3['CropType']\n",
    "    \n",
    "    # Train the model and evaluate\n",
    "    model.fit(X_train_1_2, y_train_1_2)\n",
    "    y_pred_3 = model.predict(X_test_3)\n",
    "    \n",
    "    accuracy_1_2_vs_3 = accuracy_score(y_test_3, y_pred_3)\n",
    "    print(\"Accuracy (Train: Year 1 & 2, Test: Year 3):\", accuracy_1_2_vs_3)\n",
    "    print(\"Classification Report for (Train: Year 1 & 2, Test: Year 3):\\n\", classification_report(y_test_3, y_pred_3))\n",
    "    \n",
    "    # Append results to lists for overall metrics\n",
    "    all_y_true.extend(y_test_3)\n",
    "    all_y_pred.extend(y_pred_3)\n",
    "\n",
    "    # Second combination: Train on Year 1 (2021) and Year 3 (2023), Test on Year 2 (2022)\n",
    "    train_data_1_3 = standardized_data[standardized_data['Year'].isin([2021, 2023])]\n",
    "    test_data_2 = standardized_data[standardized_data['Year'] == 2022]\n",
    "    \n",
    "    X_train_1_3 = train_data_1_3.drop(['CropType', 'Year'], axis=1)\n",
    "    y_train_1_3 = train_data_1_3['CropType']\n",
    "    X_test_2 = test_data_2.drop(['CropType', 'Year'], axis=1)\n",
    "    y_test_2 = test_data_2['CropType']\n",
    "    \n",
    "    # Train the model and evaluate\n",
    "    model.fit(X_train_1_3, y_train_1_3)\n",
    "    y_pred_2 = model.predict(X_test_2)\n",
    "    \n",
    "    accuracy_1_3_vs_2 = accuracy_score(y_test_2, y_pred_2)\n",
    "    print(\"\\nAccuracy (Train: Year 1 & 3, Test: Year 2):\", accuracy_1_3_vs_2)\n",
    "    print(\"Classification Report for (Train: Year 1 & 3, Test: Year 2):\\n\", classification_report(y_test_2, y_pred_2))\n",
    "    \n",
    "    # Append results to lists for overall metrics\n",
    "    all_y_true.extend(y_test_2)\n",
    "    all_y_pred.extend(y_pred_2)\n",
    "\n",
    "    # Third combination: Train on Year 2 (2022) and Year 3 (2023), Test on Year 1 (2021)\n",
    "    train_data_2_3 = standardized_data[standardized_data['Year'].isin([2022, 2023])]\n",
    "    test_data_1 = standardized_data[standardized_data['Year'] == 2021]\n",
    "    \n",
    "    X_train_2_3 = train_data_2_3.drop(['CropType', 'Year'], axis=1)\n",
    "    y_train_2_3 = train_data_2_3['CropType']\n",
    "    X_test_1 = test_data_1.drop(['CropType', 'Year'], axis=1)\n",
    "    y_test_1 = test_data_1['CropType']\n",
    "    \n",
    "    # Train the model and evaluate\n",
    "    model.fit(X_train_2_3, y_train_2_3)\n",
    "    y_pred_1 = model.predict(X_test_1)\n",
    "    \n",
    "    accuracy_2_3_vs_1 = accuracy_score(y_test_1, y_pred_1)\n",
    "    print(\"\\nAccuracy (Train: Year 2 & 3, Test: Year 1):\", accuracy_2_3_vs_1)\n",
    "    print(\"Classification Report for (Train: Year 2 & 3, Test: Year 1):\\n\", classification_report(y_test_1, y_pred_1))\n",
    "    \n",
    "    # Append results to lists for overall metrics\n",
    "    all_y_true.extend(y_test_1)\n",
    "    all_y_pred.extend(y_pred_1)\n",
    "\n",
    "    # Calculate overall metrics\n",
    "    overall_accuracy = accuracy_score(all_y_true, all_y_pred)\n",
    "    overall_precision = precision_score(all_y_true, all_y_pred, average='weighted')\n",
    "    overall_recall = recall_score(all_y_true, all_y_pred, average='weighted')\n",
    "    overall_f1 = f1_score(all_y_true, all_y_pred, average='weighted')\n",
    "\n",
    "    print(\"\\nOverall Metrics:\")\n",
    "    print(f\"Overall Accuracy: {overall_accuracy:.4f}\")\n",
    "    print(f\"Overall Precision: {overall_precision:.4f}\")\n",
    "    print(f\"Overall Recall: {overall_recall:.4f}\")\n",
    "    print(f\"Overall F1-Score: {overall_f1:.4f}\")\n",
    "\n",
    "# Call the function to perform cross-validation and Naive Bayes\n",
    "cross_validation_naive_bayes(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Train: Year 1 & 2, Test: Year 3): 0.8417678525940392\n",
      "Classification Report for (Train: Year 1 & 2, Test: Year 3):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.88      0.85     11777\n",
      "           1       0.87      0.81      0.84     11777\n",
      "\n",
      "    accuracy                           0.84     23554\n",
      "   macro avg       0.84      0.84      0.84     23554\n",
      "weighted avg       0.84      0.84      0.84     23554\n",
      "\n",
      "\n",
      "Accuracy (Train: Year 1 & 3, Test: Year 2): 0.7554991539763113\n",
      "Classification Report for (Train: Year 1 & 3, Test: Year 2):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.69      0.74     12411\n",
      "           1       0.73      0.82      0.77     12411\n",
      "\n",
      "    accuracy                           0.76     24822\n",
      "   macro avg       0.76      0.76      0.75     24822\n",
      "weighted avg       0.76      0.76      0.75     24822\n",
      "\n",
      "\n",
      "Accuracy (Train: Year 2 & 3, Test: Year 1): 0.8409642733263961\n",
      "Classification Report for (Train: Year 2 & 3, Test: Year 1):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84      2883\n",
      "           1       0.83      0.86      0.84      2883\n",
      "\n",
      "    accuracy                           0.84      5766\n",
      "   macro avg       0.84      0.84      0.84      5766\n",
      "weighted avg       0.84      0.84      0.84      5766\n",
      "\n",
      "\n",
      "Overall Metrics:\n",
      "Overall Accuracy: 0.8021\n",
      "Overall Precision: 0.8024\n",
      "Overall Recall: 0.8021\n",
      "Overall F1-Score: 0.8021\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Separate the features (X) and target variable (y)\n",
    "X = standardized_data.drop(['CropType', 'Year'], axis=1)  # Exclude 'CropType' and 'Year' from features\n",
    "y = standardized_data['CropType']  # Target variable ('CropType')\n",
    "\n",
    "# Function to perform cross-validation with the specified combinations using KNN\n",
    "def cross_validation_knn(X, y, n_neighbors=20):\n",
    "    # Initialize the KNN model with the specified number of neighbors\n",
    "    model = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "\n",
    "    # Create lists to store results for overall metrics\n",
    "    all_y_true = []  # List to hold true labels across all folds\n",
    "    all_y_pred = []  # List to hold predicted labels across all folds\n",
    "\n",
    "    # 1. Train on Year 1 and Year 2, Test on Year 3\n",
    "    train_data_1_2 = standardized_data[standardized_data['Year'].isin([2021, 2022])]\n",
    "    test_data_3 = standardized_data[standardized_data['Year'] == 2023]\n",
    "    \n",
    "    X_train_1_2 = train_data_1_2.drop(['CropType', 'Year'], axis=1)\n",
    "    y_train_1_2 = train_data_1_2['CropType']\n",
    "    X_test_3 = test_data_3.drop(['CropType', 'Year'], axis=1)\n",
    "    y_test_3 = test_data_3['CropType']\n",
    "    \n",
    "    # Train the model and evaluate\n",
    "    model.fit(X_train_1_2, y_train_1_2)\n",
    "    y_pred_3 = model.predict(X_test_3)\n",
    "    \n",
    "    accuracy_1_2_vs_3 = accuracy_score(y_test_3, y_pred_3)\n",
    "    print(\"Accuracy (Train: Year 1 & 2, Test: Year 3):\", accuracy_1_2_vs_3)\n",
    "    print(\"Classification Report for (Train: Year 1 & 2, Test: Year 3):\\n\", classification_report(y_test_3, y_pred_3))\n",
    "    \n",
    "    # Append results to lists for overall metrics\n",
    "    all_y_true.extend(y_test_3)\n",
    "    all_y_pred.extend(y_pred_3)\n",
    "\n",
    "    # Second combination: Train on Year 1 (2021) and Year 3 (2023), Test on Year 2 (2022)\n",
    "    train_data_1_3 = standardized_data[standardized_data['Year'].isin([2021, 2023])]\n",
    "    test_data_2 = standardized_data[standardized_data['Year'] == 2022]\n",
    "    \n",
    "    X_train_1_3 = train_data_1_3.drop(['CropType', 'Year'], axis=1)\n",
    "    y_train_1_3 = train_data_1_3['CropType']\n",
    "    X_test_2 = test_data_2.drop(['CropType', 'Year'], axis=1)\n",
    "    y_test_2 = test_data_2['CropType']\n",
    "    \n",
    "    # Train the model and evaluate\n",
    "    model.fit(X_train_1_3, y_train_1_3)\n",
    "    y_pred_2 = model.predict(X_test_2)\n",
    "    \n",
    "    accuracy_1_3_vs_2 = accuracy_score(y_test_2, y_pred_2)\n",
    "    print(\"\\nAccuracy (Train: Year 1 & 3, Test: Year 2):\", accuracy_1_3_vs_2)\n",
    "    print(\"Classification Report for (Train: Year 1 & 3, Test: Year 2):\\n\", classification_report(y_test_2, y_pred_2))\n",
    "    \n",
    "    # Append results to lists for overall metrics\n",
    "    all_y_true.extend(y_test_2)\n",
    "    all_y_pred.extend(y_pred_2)\n",
    "\n",
    "    # Third combination: Train on Year 2 (2022) and Year 3 (2023), Test on Year 1 (2021)\n",
    "    train_data_2_3 = standardized_data[standardized_data['Year'].isin([2022, 2023])]\n",
    "    test_data_1 = standardized_data[standardized_data['Year'] == 2021]\n",
    "    \n",
    "    X_train_2_3 = train_data_2_3.drop(['CropType', 'Year'], axis=1)\n",
    "    y_train_2_3 = train_data_2_3['CropType']\n",
    "    X_test_1 = test_data_1.drop(['CropType', 'Year'], axis=1)\n",
    "    y_test_1 = test_data_1['CropType']\n",
    "    \n",
    "    # Train the model and evaluate\n",
    "    model.fit(X_train_2_3, y_train_2_3)\n",
    "    y_pred_1 = model.predict(X_test_1)\n",
    "    \n",
    "    accuracy_2_3_vs_1 = accuracy_score(y_test_1, y_pred_1)\n",
    "    print(\"\\nAccuracy (Train: Year 2 & 3, Test: Year 1):\", accuracy_2_3_vs_1)\n",
    "    print(\"Classification Report for (Train: Year 2 & 3, Test: Year 1):\\n\", classification_report(y_test_1, y_pred_1))\n",
    "    \n",
    "    # Append results to lists for overall metrics\n",
    "    all_y_true.extend(y_test_1)\n",
    "    all_y_pred.extend(y_pred_1)\n",
    "\n",
    "    # Calculate overall metrics\n",
    "    overall_accuracy = accuracy_score(all_y_true, all_y_pred)\n",
    "    overall_precision = precision_score(all_y_true, all_y_pred, average='weighted')\n",
    "    overall_recall = recall_score(all_y_true, all_y_pred, average='weighted')\n",
    "    overall_f1 = f1_score(all_y_true, all_y_pred, average='weighted')\n",
    "\n",
    "    print(\"\\nOverall Metrics:\")\n",
    "    print(f\"Overall Accuracy: {overall_accuracy:.4f}\")\n",
    "    print(f\"Overall Precision: {overall_precision:.4f}\")\n",
    "    print(f\"Overall Recall: {overall_recall:.4f}\")\n",
    "    print(f\"Overall F1-Score: {overall_f1:.4f}\")\n",
    "\n",
    "# Call the function to perform cross-validation and KNN\n",
    "cross_validation_knn(X, y, n_neighbors=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Train: Year 1 & 2, Test: Year 3): 0.8513628258469899\n",
      "Classification Report for (Train: Year 1 & 2, Test: Year 3):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85     11777\n",
      "           1       0.85      0.85      0.85     11777\n",
      "\n",
      "    accuracy                           0.85     23554\n",
      "   macro avg       0.85      0.85      0.85     23554\n",
      "weighted avg       0.85      0.85      0.85     23554\n",
      "\n",
      "\n",
      "Accuracy (Train: Year 1 & 3, Test: Year 2): 0.7616630408508581\n",
      "Classification Report for (Train: Year 1 & 3, Test: Year 2):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.68      0.74     12411\n",
      "           1       0.72      0.85      0.78     12411\n",
      "\n",
      "    accuracy                           0.76     24822\n",
      "   macro avg       0.77      0.76      0.76     24822\n",
      "weighted avg       0.77      0.76      0.76     24822\n",
      "\n",
      "\n",
      "Accuracy (Train: Year 2 & 3, Test: Year 1): 0.8125216788067985\n",
      "Classification Report for (Train: Year 2 & 3, Test: Year 1):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.73      0.80      2883\n",
      "           1       0.77      0.89      0.83      2883\n",
      "\n",
      "    accuracy                           0.81      5766\n",
      "   macro avg       0.82      0.81      0.81      5766\n",
      "weighted avg       0.82      0.81      0.81      5766\n",
      "\n",
      "\n",
      "Overall Metrics:\n",
      "Overall Accuracy: 0.8061\n",
      "Overall Precision: 0.8089\n",
      "Overall Recall: 0.8061\n",
      "Overall F1-Score: 0.8057\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Separate the features (X) and target variable (y)\n",
    "X = standardized_data.drop(['CropType', 'Year'], axis=1)  # Exclude 'CropType' and 'Year' from features\n",
    "y = standardized_data['CropType']  # Target variable ('CropType')\n",
    "\n",
    "# Function to perform cross-validation with the specified combinations using Nonlinear SVM (RBF Kernel)\n",
    "def cross_validation_svm(X, y, C=1.0, gamma='scale'):\n",
    "    # Initialize the SVM classifier with the RBF kernel\n",
    "    model = SVC(kernel='rbf', C=C, gamma=gamma, random_state=42)\n",
    "\n",
    "    # Create lists to store results for overall metrics\n",
    "    all_y_true = []  # List to hold true labels across all folds\n",
    "    all_y_pred = []  # List to hold predicted labels across all folds\n",
    "\n",
    "    # 1. Train on Year 1 and Year 2, Test on Year 3\n",
    "    train_data_1_2 = standardized_data[standardized_data['Year'].isin([2021, 2022])]\n",
    "    test_data_3 = standardized_data[standardized_data['Year'] == 2023]\n",
    "    \n",
    "    X_train_1_2 = train_data_1_2.drop(['CropType', 'Year'], axis=1)\n",
    "    y_train_1_2 = train_data_1_2['CropType']\n",
    "    X_test_3 = test_data_3.drop(['CropType', 'Year'], axis=1)\n",
    "    y_test_3 = test_data_3['CropType']\n",
    "    \n",
    "    # Train the model and evaluate\n",
    "    model.fit(X_train_1_2, y_train_1_2)\n",
    "    y_pred_3 = model.predict(X_test_3)\n",
    "    \n",
    "    accuracy_1_2_vs_3 = accuracy_score(y_test_3, y_pred_3)\n",
    "    print(\"Accuracy (Train: Year 1 & 2, Test: Year 3):\", accuracy_1_2_vs_3)\n",
    "    print(\"Classification Report for (Train: Year 1 & 2, Test: Year 3):\\n\", classification_report(y_test_3, y_pred_3))\n",
    "    \n",
    "    # Append results to lists for overall metrics\n",
    "    all_y_true.extend(y_test_3)\n",
    "    all_y_pred.extend(y_pred_3)\n",
    "\n",
    "    # Second combination: Train on Year 1 (2021) and Year 3 (2023), Test on Year 2 (2022)\n",
    "    train_data_1_3 = standardized_data[standardized_data['Year'].isin([2021, 2023])]\n",
    "    test_data_2 = standardized_data[standardized_data['Year'] == 2022]\n",
    "    \n",
    "    X_train_1_3 = train_data_1_3.drop(['CropType', 'Year'], axis=1)\n",
    "    y_train_1_3 = train_data_1_3['CropType']\n",
    "    X_test_2 = test_data_2.drop(['CropType', 'Year'], axis=1)\n",
    "    y_test_2 = test_data_2['CropType']\n",
    "    \n",
    "    # Train the model and evaluate\n",
    "    model.fit(X_train_1_3, y_train_1_3)\n",
    "    y_pred_2 = model.predict(X_test_2)\n",
    "    \n",
    "    accuracy_1_3_vs_2 = accuracy_score(y_test_2, y_pred_2)\n",
    "    print(\"\\nAccuracy (Train: Year 1 & 3, Test: Year 2):\", accuracy_1_3_vs_2)\n",
    "    print(\"Classification Report for (Train: Year 1 & 3, Test: Year 2):\\n\", classification_report(y_test_2, y_pred_2))\n",
    "    \n",
    "    # Append results to lists for overall metrics\n",
    "    all_y_true.extend(y_test_2)\n",
    "    all_y_pred.extend(y_pred_2)\n",
    "\n",
    "    # Third combination: Train on Year 2 (2022) and Year 3 (2023), Test on Year 1 (2021)\n",
    "    train_data_2_3 = standardized_data[standardized_data['Year'].isin([2022, 2023])]\n",
    "    test_data_1 = standardized_data[standardized_data['Year'] == 2021]\n",
    "    \n",
    "    X_train_2_3 = train_data_2_3.drop(['CropType', 'Year'], axis=1)\n",
    "    y_train_2_3 = train_data_2_3['CropType']\n",
    "    X_test_1 = test_data_1.drop(['CropType', 'Year'], axis=1)\n",
    "    y_test_1 = test_data_1['CropType']\n",
    "    \n",
    "    # Train the model and evaluate\n",
    "    model.fit(X_train_2_3, y_train_2_3)\n",
    "    y_pred_1 = model.predict(X_test_1)\n",
    "    \n",
    "    accuracy_2_3_vs_1 = accuracy_score(y_test_1, y_pred_1)\n",
    "    print(\"\\nAccuracy (Train: Year 2 & 3, Test: Year 1):\", accuracy_2_3_vs_1)\n",
    "    print(\"Classification Report for (Train: Year 2 & 3, Test: Year 1):\\n\", classification_report(y_test_1, y_pred_1))\n",
    "    \n",
    "    # Append results to lists for overall metrics\n",
    "    all_y_true.extend(y_test_1)\n",
    "    all_y_pred.extend(y_pred_1)\n",
    "\n",
    "    # Calculate overall metrics\n",
    "    overall_accuracy = accuracy_score(all_y_true, all_y_pred)\n",
    "    overall_precision = precision_score(all_y_true, all_y_pred, average='weighted')\n",
    "    overall_recall = recall_score(all_y_true, all_y_pred, average='weighted')\n",
    "    overall_f1 = f1_score(all_y_true, all_y_pred, average='weighted')\n",
    "\n",
    "    print(\"\\nOverall Metrics:\")\n",
    "    print(f\"Overall Accuracy: {overall_accuracy:.4f}\")\n",
    "    print(f\"Overall Precision: {overall_precision:.4f}\")\n",
    "    print(f\"Overall Recall: {overall_recall:.4f}\")\n",
    "    print(f\"Overall F1-Score: {overall_f1:.4f}\")\n",
    "\n",
    "# Call the function to perform cross-validation and Nonlinear SVM (RBF Kernel)\n",
    "cross_validation_svm(X, y, C=1.0, gamma='scale')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],           # Regularization parameter\n",
    "    'gamma': [0.01, 0.1, 1, 10],      # Kernel coefficient\n",
    "    'kernel': ['rbf']                 # Use RBF kernel\n",
    "}\n",
    "\n",
    "# Initialize the SVM classifier\n",
    "svm = SVC()\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=svm, param_grid=param_grid, cv=3, scoring='accuracy', verbose=1)\n",
    "\n",
    "# Perform Grid Search\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Get the best parameters and the best score\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "print(\"Best Cross-Validation Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "# Function to perform cross-validation with the best parameters found by Grid Search\n",
    "def cross_validation_svm_best_params(X, y, best_params):\n",
    "    # Initialize the SVM classifier with the best parameters\n",
    "    model = SVC(**best_params, random_state=42)\n",
    "\n",
    "    # Create lists to store results for overall metrics\n",
    "    all_y_true = []  # List to hold true labels across all folds\n",
    "    all_y_pred = []  # List to hold predicted labels across all folds\n",
    "\n",
    "    # 1. Train on Year 1 and Year 2, Test on Year 3\n",
    "    train_data_1_2 = standardized_data[standardized_data['Year'].isin([2021, 2022])]\n",
    "    test_data_3 = standardized_data[standardized_data['Year'] == 2023]\n",
    "    \n",
    "    X_train_1_2 = train_data_1_2.drop(['CropType', 'Year'], axis=1)\n",
    "    y_train_1_2 = train_data_1_2['CropType']\n",
    "    X_test_3 = test_data_3.drop(['CropType', 'Year'], axis=1)\n",
    "    y_test_3 = test_data_3['CropType']\n",
    "    \n",
    "    # Train the model and evaluate\n",
    "    model.fit(X_train_1_2, y_train_1_2)\n",
    "    y_pred_3 = model.predict(X_test_3)\n",
    "    \n",
    "    accuracy_1_2_vs_3 = accuracy_score(y_test_3, y_pred_3)\n",
    "    print(\"Accuracy (Train: Year 1 & 2, Test: Year 3):\", accuracy_1_2_vs_3)\n",
    "    print(\"Classification Report for (Train: Year 1 & 2, Test: Year 3):\\n\", classification_report(y_test_3, y_pred_3))\n",
    "    \n",
    "    # Append results to lists for overall metrics\n",
    "    all_y_true.extend(y_test_3)\n",
    "    all_y_pred.extend(y_pred_3)\n",
    "\n",
    "    # Second combination: Train on Year 1 (2021) and Year 3 (2023), Test on Year 2 (2022)\n",
    "    train_data_1_3 = standardized_data[standardized_data['Year'].isin([2021, 2023])]\n",
    "    test_data_2 = standardized_data[standardized_data['Year'] == 2022]\n",
    "    \n",
    "    X_train_1_3 = train_data_1_3.drop(['CropType', 'Year'], axis=1)\n",
    "    y_train_1_3 = train_data_1_3['CropType']\n",
    "    X_test_2 = test_data_2.drop(['CropType', 'Year'], axis=1)\n",
    "    y_test_2 = test_data_2['CropType']\n",
    "    \n",
    "    # Train the model and evaluate\n",
    "    model.fit(X_train_1_3, y_train_1_3)\n",
    "    y_pred_2 = model.predict(X_test_2)\n",
    "    \n",
    "    accuracy_1_3_vs_2 = accuracy_score(y_test_2, y_pred_2)\n",
    "    print(\"\\nAccuracy (Train: Year 1 & 3, Test: Year 2):\", accuracy_1_3_vs_2)\n",
    "    print(\"Classification Report for (Train: Year 1 & 3, Test: Year 2):\\n\", classification_report(y_test_2, y_pred_2))\n",
    "    \n",
    "    # Append results to lists for overall metrics\n",
    "    all_y_true.extend(y_test_2)\n",
    "    all_y_pred.extend(y_pred_2)\n",
    "\n",
    "    # Third combination: Train on Year 2 (2022) and Year 3 (2023), Test on Year 1 (2021)\n",
    "    train_data_2_3 = standardized_data[standardized_data['Year'].isin([2022, 2023])]\n",
    "    test_data_1 = standardized_data[standardized_data['Year'] == 2021]\n",
    "    \n",
    "    X_train_2_3 = train_data_2_3.drop(['CropType', 'Year'], axis=1)\n",
    "    y_train_2_3 = train_data_2_3['CropType']\n",
    "    X_test_1 = test_data_1.drop(['CropType', 'Year'], axis=1)\n",
    "    y_test_1 = test_data_1['CropType']\n",
    "    \n",
    "    # Train the model and evaluate\n",
    "    model.fit(X_train_2_3, y_train_2_3)\n",
    "    y_pred_1 = model.predict(X_test_1)\n",
    "    \n",
    "    accuracy_2_3_vs_1 = accuracy_score(y_test_1, y_pred_1)\n",
    "    print(\"\\nAccuracy (Train: Year 2 & 3, Test: Year 1):\", accuracy_2_3_vs_1)\n",
    "    print(\"Classification Report for (Train: Year 2 & 3, Test: Year 1):\\n\", classification_report(y_test_1, y_pred_1))\n",
    "    \n",
    "    # Append results to lists for overall metrics\n",
    "    all_y_true.extend(y_test_1)\n",
    "    all_y_pred.extend(y_pred_1)\n",
    "\n",
    "    # Calculate overall metrics\n",
    "    overall_accuracy = accuracy_score(all_y_true, all_y_pred)\n",
    "    overall_precision = precision_score(all_y_true, all_y_pred, average='weighted')\n",
    "    overall_recall = recall_score(all_y_true, all_y_pred, average='weighted')\n",
    "    overall_f1 = f1_score(all_y_true, all_y_pred, average='weighted')\n",
    "\n",
    "    print(\"\\nOverall Metrics:\")\n",
    "    print(f\"Overall Accuracy: {overall_accuracy:.4f}\")\n",
    "    print(f\"Overall Precision: {overall_precision:.4f}\")\n",
    "    print(f\"Overall Recall: {overall_recall:.4f}\")\n",
    "    print(f\"Overall F1-Score: {overall_f1:.4f}\")\n",
    "\n",
    "# Perform cross-validation with the best parameters found by Grid Search\n",
    "cross_validation_svm_best_params(X, y, grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NDVI01</th>\n",
       "      <th>NDVI02</th>\n",
       "      <th>NDVI03</th>\n",
       "      <th>NDVI04</th>\n",
       "      <th>NDVI05</th>\n",
       "      <th>NDVI06</th>\n",
       "      <th>NDVI07</th>\n",
       "      <th>NDVI08</th>\n",
       "      <th>NDVI09</th>\n",
       "      <th>NDVI10</th>\n",
       "      <th>NDVI11</th>\n",
       "      <th>NDVI12</th>\n",
       "      <th>Year</th>\n",
       "      <th>CropType_rice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.049580</td>\n",
       "      <td>0.377865</td>\n",
       "      <td>1.327950</td>\n",
       "      <td>0.745377</td>\n",
       "      <td>-1.139121</td>\n",
       "      <td>-0.866922</td>\n",
       "      <td>-0.298620</td>\n",
       "      <td>-0.362663</td>\n",
       "      <td>-0.266806</td>\n",
       "      <td>-0.408408</td>\n",
       "      <td>-0.118629</td>\n",
       "      <td>-0.070738</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.588665</td>\n",
       "      <td>-0.651236</td>\n",
       "      <td>-0.259306</td>\n",
       "      <td>-1.483758</td>\n",
       "      <td>-0.618092</td>\n",
       "      <td>-1.146289</td>\n",
       "      <td>0.190041</td>\n",
       "      <td>0.053859</td>\n",
       "      <td>0.260648</td>\n",
       "      <td>0.309821</td>\n",
       "      <td>0.093379</td>\n",
       "      <td>-0.122052</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.707691</td>\n",
       "      <td>1.541768</td>\n",
       "      <td>-0.407288</td>\n",
       "      <td>-0.407209</td>\n",
       "      <td>-0.382650</td>\n",
       "      <td>-0.460573</td>\n",
       "      <td>-0.010038</td>\n",
       "      <td>-0.018230</td>\n",
       "      <td>0.575779</td>\n",
       "      <td>0.583402</td>\n",
       "      <td>0.390439</td>\n",
       "      <td>-0.303053</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.424230</td>\n",
       "      <td>-0.720145</td>\n",
       "      <td>-1.144157</td>\n",
       "      <td>-0.916241</td>\n",
       "      <td>-1.158653</td>\n",
       "      <td>-0.798600</td>\n",
       "      <td>-1.685207</td>\n",
       "      <td>-1.103992</td>\n",
       "      <td>-0.329530</td>\n",
       "      <td>-0.238256</td>\n",
       "      <td>-1.127021</td>\n",
       "      <td>-0.891429</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.205602</td>\n",
       "      <td>-0.227110</td>\n",
       "      <td>-0.164380</td>\n",
       "      <td>-0.970849</td>\n",
       "      <td>-0.250413</td>\n",
       "      <td>0.630402</td>\n",
       "      <td>-0.807126</td>\n",
       "      <td>-0.341660</td>\n",
       "      <td>0.366198</td>\n",
       "      <td>0.564641</td>\n",
       "      <td>0.091184</td>\n",
       "      <td>-1.856336</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     NDVI01    NDVI02    NDVI03    NDVI04    NDVI05    NDVI06    NDVI07  \\\n",
       "0  0.049580  0.377865  1.327950  0.745377 -1.139121 -0.866922 -0.298620   \n",
       "1 -0.588665 -0.651236 -0.259306 -1.483758 -0.618092 -1.146289  0.190041   \n",
       "2  0.707691  1.541768 -0.407288 -0.407209 -0.382650 -0.460573 -0.010038   \n",
       "3 -0.424230 -0.720145 -1.144157 -0.916241 -1.158653 -0.798600 -1.685207   \n",
       "4  0.205602 -0.227110 -0.164380 -0.970849 -0.250413  0.630402 -0.807126   \n",
       "\n",
       "     NDVI08    NDVI09    NDVI10    NDVI11    NDVI12    Year  CropType_rice  \n",
       "0 -0.362663 -0.266806 -0.408408 -0.118629 -0.070738  2021.0          False  \n",
       "1  0.053859  0.260648  0.309821  0.093379 -0.122052  2021.0          False  \n",
       "2 -0.018230  0.575779  0.583402  0.390439 -0.303053  2021.0          False  \n",
       "3 -1.103992 -0.329530 -0.238256 -1.127021 -0.891429  2021.0          False  \n",
       "4 -0.341660  0.366198  0.564641  0.091184 -1.856336  2021.0          False  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data = pd.get_dummies(combined_data,columns=['CropType'], drop_first=True)\n",
    "combined_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data [\"CropType_rice\"]=combined_data [\"CropType_rice\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NDVI01</th>\n",
       "      <th>NDVI02</th>\n",
       "      <th>NDVI03</th>\n",
       "      <th>NDVI04</th>\n",
       "      <th>NDVI05</th>\n",
       "      <th>NDVI06</th>\n",
       "      <th>NDVI07</th>\n",
       "      <th>NDVI08</th>\n",
       "      <th>NDVI09</th>\n",
       "      <th>NDVI10</th>\n",
       "      <th>NDVI11</th>\n",
       "      <th>NDVI12</th>\n",
       "      <th>Year</th>\n",
       "      <th>CropType_rice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54137</th>\n",
       "      <td>-0.205353</td>\n",
       "      <td>-0.112100</td>\n",
       "      <td>1.258188</td>\n",
       "      <td>1.188694</td>\n",
       "      <td>0.924563</td>\n",
       "      <td>1.051466</td>\n",
       "      <td>-0.263769</td>\n",
       "      <td>-2.071469</td>\n",
       "      <td>-0.801376</td>\n",
       "      <td>0.826108</td>\n",
       "      <td>1.045835</td>\n",
       "      <td>0.660351</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54138</th>\n",
       "      <td>-0.280154</td>\n",
       "      <td>0.083541</td>\n",
       "      <td>0.604075</td>\n",
       "      <td>0.911046</td>\n",
       "      <td>0.950719</td>\n",
       "      <td>-0.964842</td>\n",
       "      <td>0.471268</td>\n",
       "      <td>-0.467847</td>\n",
       "      <td>-1.667553</td>\n",
       "      <td>-2.219850</td>\n",
       "      <td>-2.011028</td>\n",
       "      <td>-1.803134</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54139</th>\n",
       "      <td>0.500908</td>\n",
       "      <td>1.257706</td>\n",
       "      <td>0.986469</td>\n",
       "      <td>1.163840</td>\n",
       "      <td>0.904660</td>\n",
       "      <td>1.082565</td>\n",
       "      <td>0.234851</td>\n",
       "      <td>-0.411928</td>\n",
       "      <td>-0.612794</td>\n",
       "      <td>0.691721</td>\n",
       "      <td>1.211483</td>\n",
       "      <td>1.124318</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54140</th>\n",
       "      <td>-0.174454</td>\n",
       "      <td>1.741256</td>\n",
       "      <td>1.686756</td>\n",
       "      <td>1.080027</td>\n",
       "      <td>0.751973</td>\n",
       "      <td>0.465149</td>\n",
       "      <td>-2.211973</td>\n",
       "      <td>-0.053013</td>\n",
       "      <td>0.954455</td>\n",
       "      <td>1.128675</td>\n",
       "      <td>1.067586</td>\n",
       "      <td>0.939649</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54141</th>\n",
       "      <td>-0.382509</td>\n",
       "      <td>2.969715</td>\n",
       "      <td>-1.485162</td>\n",
       "      <td>-1.745611</td>\n",
       "      <td>-2.738115</td>\n",
       "      <td>-1.435866</td>\n",
       "      <td>-1.253626</td>\n",
       "      <td>0.094000</td>\n",
       "      <td>1.550876</td>\n",
       "      <td>0.795901</td>\n",
       "      <td>0.815635</td>\n",
       "      <td>0.672978</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         NDVI01    NDVI02    NDVI03    NDVI04    NDVI05    NDVI06    NDVI07  \\\n",
       "54137 -0.205353 -0.112100  1.258188  1.188694  0.924563  1.051466 -0.263769   \n",
       "54138 -0.280154  0.083541  0.604075  0.911046  0.950719 -0.964842  0.471268   \n",
       "54139  0.500908  1.257706  0.986469  1.163840  0.904660  1.082565  0.234851   \n",
       "54140 -0.174454  1.741256  1.686756  1.080027  0.751973  0.465149 -2.211973   \n",
       "54141 -0.382509  2.969715 -1.485162 -1.745611 -2.738115 -1.435866 -1.253626   \n",
       "\n",
       "         NDVI08    NDVI09    NDVI10    NDVI11    NDVI12  Year  CropType_rice  \n",
       "54137 -2.071469 -0.801376  0.826108  1.045835  0.660351   NaN              1  \n",
       "54138 -0.467847 -1.667553 -2.219850 -2.011028 -1.803134   NaN              1  \n",
       "54139 -0.411928 -0.612794  0.691721  1.211483  1.124318   NaN              1  \n",
       "54140 -0.053013  0.954455  1.128675  1.067586  0.939649   NaN              1  \n",
       "54141  0.094000  1.550876  0.795901  0.815635  0.672978   NaN              1  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year\n",
       "2022.0    17098\n",
       "2023.0    12696\n",
       "2021.0     3302\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance (Train on 2021.0 and 2021.0, Test on 2023.0): 0.8783\n",
      "Model performance (Train on 2021.0 and 2021.0, Test on 2022.0): 0.7654\n",
      "Model performance (Train on 2022.0 and 2022.0, Test on 2021.0): 0.8937\n",
      "Average Model Accuracy: 0.8458\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming combined_data is the DataFrame you have after processing the datasets for 2021, 2022, and 2023\n",
    "\n",
    "# Step 1: Prepare the dataset\n",
    "X = combined_data.drop(['CropType', 'Year'], axis=1)  # Features (excluding 'CropType' and 'Year')\n",
    "y = combined_data['CropType']  # Target variable\n",
    "\n",
    "# Step 2: Define the cross-validation splits\n",
    "# We will use custom cross-validation based on the 'Year' column\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Custom Cross-Validation Split based on the Year\n",
    "cv_splits = [\n",
    "    (combined_data[combined_data['Year'].isin([2021, 2022])], combined_data[combined_data['Year'] == 2023]),\n",
    "    (combined_data[combined_data['Year'].isin([2021, 2023])], combined_data[combined_data['Year'] == 2022]),\n",
    "    (combined_data[combined_data['Year'].isin([2022, 2023])], combined_data[combined_data['Year'] == 2021]),\n",
    "]\n",
    "\n",
    "# Step 3: Initialize Logistic Regression model\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Step 4: Evaluate the model using custom cross-validation\n",
    "results = []\n",
    "\n",
    "for train_data, test_data in cv_splits:\n",
    "    # Extract features and target variable for training and testing\n",
    "    X_train = train_data.drop(['CropType', 'Year'], axis=1)\n",
    "    y_train = train_data['CropType']\n",
    "    \n",
    "    X_test = test_data.drop(['CropType', 'Year'], axis=1)\n",
    "    y_test = test_data['CropType']\n",
    "    \n",
    "    # Fit the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate the accuracy score\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    results.append(accuracy)\n",
    "    print(f\"Model performance (Train on {train_data['Year'].iloc[0]} and {train_data['Year'].iloc[1]}, Test on {test_data['Year'].iloc[0]}): {accuracy:.4f}\")\n",
    "\n",
    "# Step 5: Calculate the average accuracy\n",
    "average_accuracy = sum(results) / len(results)\n",
    "print(f\"Average Model Accuracy: {average_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid classes inferred from unique values of `y`.  Expected: [0 1], got ['cotton' 'rice']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m y_test \u001b[38;5;241m=\u001b[39m test_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCropType\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Fit the model on the training data\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Predict on the test data\u001b[39;00m\n\u001b[0;32m     22\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m xgb_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\sklearn.py:1491\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[0;32m   1486\u001b[0m     expected_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m   1487\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1488\u001b[0m     classes\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m expected_classes\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m   1489\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (classes \u001b[38;5;241m==\u001b[39m expected_classes)\u001b[38;5;241m.\u001b[39mall()\n\u001b[0;32m   1490\u001b[0m ):\n\u001b[1;32m-> 1491\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1492\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid classes inferred from unique values of `y`.  \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1493\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_classes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclasses\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1494\u001b[0m     )\n\u001b[0;32m   1496\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_xgb_params()\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid classes inferred from unique values of `y`.  Expected: [0 1], got ['cotton' 'rice']"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize XGBoost model\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "\n",
    "# Step 1: Train and evaluate the model using custom cross-validation\n",
    "xgb_results = []\n",
    "\n",
    "for train_data, test_data in cv_splits:\n",
    "    # Extract features and target variable for training and testing\n",
    "    X_train = train_data.drop(['CropType', 'Year'], axis=1)\n",
    "    y_train = train_data['CropType']\n",
    "    \n",
    "    X_test = test_data.drop(['CropType', 'Year'], axis=1)\n",
    "    y_test = test_data['CropType']\n",
    "    \n",
    "    # Fit the model on the training data\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test data\n",
    "    y_pred = xgb_model.predict(X_test)\n",
    "    \n",
    "    # Calculate the accuracy score\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    xgb_results.append(accuracy)\n",
    "    print(f\"XGBoost Model performance (Train on {train_data['Year'].iloc[0]} and {train_data['Year'].iloc[1]}, Test on {test_data['Year'].iloc[0]}): {accuracy:.4f}\")\n",
    "\n",
    "# Step 2: Calculate the average accuracy for XGBoost\n",
    "xgb_avg_accuracy = sum(xgb_results) / len(xgb_results)\n",
    "print(f\"Average XGBoost Model Accuracy: {xgb_avg_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
